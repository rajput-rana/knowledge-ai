# Knowledge AI

A production-grade **Retrieval-Augmented Generation (RAG)** system with advanced AI capabilities including agentic AI, reasoning models, and Model Context Protocol (MCP) support.

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

---

## ğŸ¯ Overview

Knowledge AI is a comprehensive RAG system that combines multiple AI concepts:

- âœ… **LLM** - Large Language Models for generation
- âœ… **RAG** - Retrieval-Augmented Generation
- âœ… **Prompt Engineering** - Enhanced prompts with templates
- âœ… **Vector Search** - Semantic similarity search
- âœ… **Agentic AI** - Autonomous agents with tool use
- âœ… **Reasoning Models** - Large reasoning models (o1, etc.)
- âœ… **MCP** - Model Context Protocol integration

---

## âœ¨ Key Features

### Core RAG Capabilities
- ğŸ“š **Document Ingestion**: Chunk documents with overlap and metadata
- ğŸ” **Semantic Search**: FAISS-based vector similarity search
- ğŸ’¬ **Context-Aware Answers**: Generate answers using retrieved context
- ğŸ“Š **Source Attribution**: Every answer includes document references

### Advanced AI Features
- ğŸ¤– **Agentic AI**: Autonomous agents that use tools and make decisions
- ğŸ§  **Reasoning Models**: Support for reasoning-optimized models (o1, Claude reasoning)
- ğŸ¨ **Enhanced Prompts**: Multiple prompt styles (standard, chain-of-thought, few-shot)
- ğŸ”Œ **MCP Integration**: Expose capabilities as standardized MCP tools

### Production-Ready
- ğŸš€ **Modern Web UI**: Clean, intuitive interface
- ğŸ”Œ **RESTful API**: Full API access with OpenAPI docs
- ğŸ”„ **Async-First**: Built for performance with async/await
- ğŸ§© **Modular Design**: Easy to extend and customize
- ğŸ”’ **Type-Safe**: Full type hints throughout
- ğŸ“ **Well-Documented**: Comprehensive documentation

---

## ğŸ›  Technology Stack

### Core Framework
- **[FastAPI](https://fastapi.tiangolo.com/)** - Modern, fast web framework
- **[Uvicorn](https://www.uvicorn.org/)** - ASGI server
- **[Pydantic](https://docs.pydantic.dev/)** - Data validation and settings

### AI & ML
- **[OpenAI API](https://platform.openai.com/)** - Embeddings and chat completion
- **[FAISS](https://github.com/facebookresearch/faiss)** - Vector similarity search
- **[NumPy](https://numpy.org/)** - Numerical computing

### Protocols & Standards
- **MCP (Model Context Protocol)** - Standardized tool interface
- **OpenAPI** - API documentation standard

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10 or higher
- OpenAI API key (or compatible API)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd knowledge-ai
   ```

2. **Create virtual environment**
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

4. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env and add your API keys
   ```

5. **Start the server**
   ```bash
   python -m app.main
   # or
   uvicorn app.main:app --reload
   ```

6. **Access the application**
   - Web UI: http://localhost:8000
   - API Docs: http://localhost:8000/docs
   - Health Check: http://localhost:8000/health

---

## ğŸ“– Usage Guide

### Web UI

The easiest way to interact with Knowledge AI:

1. **Ingest Documents**
   - Go to "Ingest Document" tab
   - Paste your document text
   - Optionally add metadata as JSON
   - Click "Ingest Document"

2. **Query Knowledge Base**
   - Go to "Query Knowledge Base" tab
   - Enter your question
   - Choose options:
     - **Prompt Style**: Standard, Chain-of-Thought, Few-Shot, or Reasoning
     - **Agentic AI Mode**: Enable autonomous agent
     - **Reasoning Model**: Use reasoning-optimized model
   - Click "Get Answer"

### API Endpoints

#### Ingest Document
```bash
curl -X POST "http://localhost:8000/api/v1/ingest" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Your document text here...",
    "metadata": {"source": "docs"}
  }'
```

#### Query with Standard RAG
```bash
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What is RAG?",
    "prompt_style": "chain_of_thought"
  }'
```

#### Query with Agentic AI
```bash
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What is RAG?",
    "use_agent": true
  }'
```

#### Query with Reasoning Model
```bash
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Explain how RAG works step by step",
    "use_reasoning": true
  }'
```

### MCP Tools

#### List Available Tools
```bash
curl "http://localhost:8000/api/v1/mcp/tools"
```

#### Call MCP Tool
```bash
curl -X POST "http://localhost:8000/api/v1/mcp/tools/query_knowledge_base" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What is machine learning?",
    "prompt_style": "chain_of_thought",
    "top_k": 5
  }'
```

---

## ğŸ— Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI Application                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   Web UI     â”‚              â”‚  REST API    â”‚            â”‚
â”‚  â”‚  (Static)    â”‚              â”‚  Endpoints   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      RAG Pipeline            â”‚
          â”‚  + Agentic AI                â”‚
          â”‚  + Reasoning Models          â”‚
          â”‚  + Enhanced Prompts          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚              â”‚               â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ Retriever â”‚  â”‚ Chat LLM  â”‚  â”‚  Ingest   â”‚
    â”‚  + Agent  â”‚  â”‚ + Reason  â”‚  â”‚  + MCP    â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚                             â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Vector Store â”‚            â”‚  Chunker        â”‚
    â”‚  (FAISS)    â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
          â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”              â”‚  Embedder   â”‚
    â”‚ Embeddings â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
```

### AI Concepts Covered

1. **LLM (Large Language Model)**
   - OpenAI-compatible chat completion
   - Configurable models (gpt-4o-mini, etc.)

2. **RAG (Retrieval-Augmented Generation)**
   - Document retrieval â†’ Context building â†’ Answer generation
   - Source attribution and citation

3. **Prompt Engineering**
   - Multiple prompt styles
   - Chain-of-thought reasoning
   - Few-shot examples
   - Custom instructions

4. **Vector Search**
   - FAISS-based similarity search
   - Configurable dimensions and metrics
   - Metadata filtering

5. **Agentic AI**
   - Autonomous agents with tool use
   - Multi-step reasoning
   - Execution trace tracking
   - Tool composition

6. **Reasoning Models**
   - Support for reasoning-optimized models (o1)
   - Automatic routing based on query complexity
   - Step-by-step reasoning display

7. **MCP (Model Context Protocol)**
   - Expose RAG as standardized tools
   - Connect to external MCP servers
   - Tool discovery and execution

---

## ğŸ“ Project Structure

```
knowledge-ai/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                    # FastAPI routes and schemas
â”‚   â”‚   â”œâ”€â”€ routes.py          # Route handlers
â”‚   â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                 # Agentic AI system
â”‚   â”‚   â”œâ”€â”€ base.py            # Base agent classes
â”‚   â”‚   â”œâ”€â”€ rag_agent.py       # RAG agent implementation
â”‚   â”‚   â””â”€â”€ tools.py           # Built-in tools
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                   # Core utilities
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â”‚   â””â”€â”€ logging.py         # Logging setup
â”‚   â”‚
â”‚   â”œâ”€â”€ embeddings/             # Embedding generation
â”‚   â”‚   â””â”€â”€ embedder.py        # OpenAI embedder
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/              # Document processing
â”‚   â”‚   â”œâ”€â”€ loader.py          # Document loading
â”‚   â”‚   â””â”€â”€ chunker.py         # Text chunking
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                    # LLM integration
â”‚   â”‚   â”œâ”€â”€ chat.py            # Chat completion
â”‚   â”‚   â””â”€â”€ reasoning.py       # Reasoning models
â”‚   â”‚
â”‚   â”œâ”€â”€ mcp/                    # MCP integration
â”‚   â”‚   â”œâ”€â”€ server.py          # MCP server
â”‚   â”‚   â””â”€â”€ client.py          # MCP client
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/                # Prompt templates
â”‚   â”‚   â””â”€â”€ templates.py       # Enhanced prompts
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                    # RAG pipeline
â”‚   â”‚   â””â”€â”€ pipeline.py        # End-to-end RAG
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/              # Retrieval logic
â”‚   â”‚   â””â”€â”€ retriever.py       # Query retrieval
â”‚   â”‚
â”‚   â”œâ”€â”€ static/                 # Web UI
â”‚   â”‚   â”œâ”€â”€ index.html         # Main page
â”‚   â”‚   â”œâ”€â”€ styles.css         # Styling
â”‚   â”‚   â””â”€â”€ app.js             # Frontend logic
â”‚   â”‚
â”‚   â”œâ”€â”€ vector_store/           # Vector storage
â”‚   â”‚   â””â”€â”€ faiss_store.py     # FAISS implementation
â”‚   â”‚
â”‚   â””â”€â”€ main.py                 # FastAPI app entry point
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md         # Architecture documentation
â”‚   â””â”€â”€ mcp.md                  # MCP integration guide
â”‚
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

---

## âš™ï¸ Configuration

### Environment Variables

**Required:**
- `EMBEDDING_API_KEY` - API key for embeddings
- `CHAT_API_KEY` - API key for chat completion

**Optional:**
- `PROMPT_STYLE` - Prompt style (standard, chain_of_thought, few_shot, reasoning)
- `ENABLE_AGENTIC_MODE` - Enable agentic AI (default: true)
- `REASONING_API_KEY` - API key for reasoning models
- `ENABLE_MCP_SERVER` - Enable MCP server (default: true)

See `.env.example` for all configuration options.

---

## ğŸ§ª Examples

### Example 1: Basic RAG Query

```python
import httpx

async with httpx.AsyncClient() as client:
    # Ingest document
    await client.post("http://localhost:8000/api/v1/ingest", json={
        "text": "RAG combines retrieval with generation...",
        "metadata": {"source": "docs"}
    })
    
    # Query
    response = await client.post("http://localhost:8000/api/v1/query", json={
        "query": "What is RAG?"
    })
    print(response.json()["answer"])
```

### Example 2: Agentic Query

```python
response = await client.post("http://localhost:8000/api/v1/query", json={
    "query": "Find and summarize information about machine learning",
    "use_agent": True
})

result = response.json()
print(f"Answer: {result['answer']}")
print(f"Agent trace: {result['agent_trace']}")
```

### Example 3: Using MCP Tools

```python
# List tools
tools = await client.get("http://localhost:8000/api/v1/mcp/tools")

# Call tool
result = await client.post(
    "http://localhost:8000/api/v1/mcp/tools/query_knowledge_base",
    json={"query": "What is AI?", "prompt_style": "chain_of_thought"}
)
print(result.json()["result"])
```

---

## ğŸ”§ Development

### Running Tests

```bash
pytest
```

### Code Style

```bash
black app/
flake8 app/
mypy app/
```

### Adding New Features

1. Create feature branch
2. Implement changes
3. Add tests
4. Update documentation
5. Submit pull request

---

## ğŸ“š Documentation

- [Architecture Documentation](docs/architecture.md) - System design and decisions
- [MCP Integration Guide](docs/mcp.md) - MCP protocol usage
- [API Documentation](http://localhost:8000/docs) - Interactive API docs

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

---

## ğŸ“„ License

[Add your license here]

---

## ğŸ™ Acknowledgments

- [FastAPI](https://fastapi.tiangolo.com/) - Excellent web framework
- [FAISS](https://github.com/facebookresearch/faiss) - Vector search
- [OpenAI](https://openai.com/) - AI models and APIs
- The open-source community

---

**Built with â¤ï¸ for the AI community**
